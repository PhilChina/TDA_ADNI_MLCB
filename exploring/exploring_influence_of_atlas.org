#+BIND: org-export-use-babel nil
#+TITLE: Exploring the influence of the choice of Brain Atlas on Topological Descriptors
#+AUTHOR: Philip Hartout
#+EMAIL: <philip.hartout@protonmail.com>
#+DATE: September 25, 2020
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS:[a4paper,12pt,twoside]
#+LaTeX_HEADER:\usepackage[usenames,dvipsnames,figures]{xcolor}
#+LaTeX_HEADER:\usepackage[autostyle]{csquotes}
#+LaTeX_HEADER:\usepackage[final]{pdfpages}
#+LaTeX_HEADER:\usepackage[top=3cm, bottom=3cm, left=3cm, right=3cm]{geometry}
#+LATEX_HEADER_EXTRA:\hypersetup{colorlinks=false, linkcolor=black, citecolor=black, filecolor=black, urlcolor=black}
#+LATEX_HEADER_EXTRA:\newtheorem{definition}{Definition}[section]
#+LATEX_HEADER_EXTRA:\pagestyle{fancy}
#+LATEX_HEADER_EXTRA:\setlength{\headheight}{25pt}
#+LATEX_HEADER_EXTRA:\lhead{\textbf{Philip Hartout}}
#+LATEX_HEADER_EXTRA:\rhead{\textbf{}}
#+LATEX_HEADER_EXTRA:\rfoot{}
#+MACRO: NEWLINE @@latex:\\@@ @@html:<br>@@
#+PROPERTY: header-args :exports both :session python_emacs_session :cache :results value
#+OPTIONS: ^:nil
#+TODO: TODO IN-PROGRESS WAITING | DONE CANCELED
#+STARTUP: latexpreview
#+LATEX_COMPILER: pdflatexorg-mode restarted

* Context
This document explores the influence of the choice of brain atlas on
the measure of topological descriptors. Concretely:
1. we list a set of possible atlases used in research
2. use these on the ADNI dataset to extract graphs
3. compute the topological descriptors of these graphs
4. make a statistical analysis of these descriptors

* List of possible atlases to use
** Found independently
- [[https://www.sciencedirect.com/science/article/pii/S1053811920306121][Dictionary of Functional Modes for brain imaging]],
website: https://parietal-inria.github.io/DiFuMo/
code: https://github.com/Parietal-INRIA/DiFuMo
codename: Dadi et al
- [[https://pubmed.ncbi.nlm.nih.gov/26523655/][A human brain atlas derived via n-cut parcellation of resting-state and task-based fMRI data]] website:
https://www.nitrc.org/docman/index.php?group_id=989&selected_doc_group_id=3875&language_id=1#folder
codename: James et al
- [[https://www.sciencedirect.com/science/article/pii/S1053811910008542?via%3Dihub][Automatic parcellation of human cortical gyri and sulci using
  standard anatomical nomenclature]]
used here:
https://nilearn.github.io/auto_examples/01_plotting/plot_surf_atlas.html
codename: Destrieux et al
- An automated labeling system for subdividing the human cerebral
  cortex on MRI scans into gyral based regions of interest
codename Desikan et al
- Multi-subject dictionary learning to segment an atlas of brain
  spontaneous activity
codename: Varoquaux et al
** Found in the literature
- In "Uncovering the Topology of Time-Varying fMRI Data using Cubical Persistence"
paper: https://pubmed.ncbi.nlm.nih.gov/28981612/
code:
https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal
codename: Schaefer et al
** Current list of atlases considered
- Dadi et al
- James et al
- Destrieux et al
- Schaefer et al
- Desikan et al
- Varoquaux et al

* General background & definitions.
** General
- Alzheimer's disease: Alzheimer’s disease is an irreversible,
progressive brain disorder that slowly destroys memory and thinking
skills and, eventually, the ability to carry out the simplest tasks.
In most people with the disease—those with the late-onset
type—symptoms first appear in their mid-60s. Early-onset Alzheimer’s
occurs between a person’s 30s and mid-60s and is very rare.
Alzheimer’s disease is the most common cause of dementia among older
adults. Source:
https://www.nia.nih.gov/health/what-alzheimers-disease

- Structural MRI (sMRI): Structural magnetic resonance imaging (sMRI)
  is a technique for measuring the anatomy of the brain. By measuring
  the amount of water at a given location, sMRI is capable of
  acquiring a detailed anatomical picture of our brain. This allows us
  to accurately distinguish between different types of tissue, such as
  gray and white matter. Structural images are high-resolution images
  of the brain that are used as reference images for multiple
  purposes, such as corregistration, normalization, segmentation, and
  surface reconstruction.

As there is no time pressure during
acquisition of anatomical images (the anatomy is not supposed to
change while the person is in the scanner), a higher resolution can be
used for recording anatomical images, with a voxel extent of 0.2 to
1.5mm, depending on the strength of the magnetic field in the scanner,
e.g. 1.5T, 3T or 7T. Grey matter structures are seen in dark, and the
white matter structures in bright colors. Source:


** sMRI preprocessing steps ([[https://miykael.github.io/nipype-beginner-s-guide/neuroimaging.html][source]])
*** Coregistration
Motion correction aligns all the images within a volume so they are
‘aligned’. Coregistration aligns the functional image with the
reference structural image. If you think of the functional image as
having been printed on tracing paper, coregistration moves that image
around on the reference image until the alignment is at its best. In
other words, coregistration tries to superimpose the functional image
perfectly on the anatomical image. This allows further transformations
of the anatomical image, such as normalization, to be directly applied
to the functional image. The following picture shows an example of
good (top) and bad (bottom) coregistration of functional images with
the corresponding anatomical images. The red lines are the outline of
the cortical folds of the anatomical image superimposed on the
underlying greyscale functional image.

#+ATTR_ORG: :width 800
[[./images/coregistration.png]]

*** Normalization
Every person’s brain is slightly different from every other’s. Brains
differ in size and shape. To compare the images of one person’s brain
to another’s, the images must first be translated onto a common shape
and size, which is called normalization. Normalization maps data from
the individual subject-space it was measured in onto a
reference-space. Once this step is completed, a group analysis or
comparison among data can be performed. There are different ways to
normalize data but it always includes a template and a source image.

#+ATTR_ORG: :width 1000
[[./images/normalization.png]]

    - The template image is the standard brain in reference-space onto
    which you want to map your data. This can be a Talairach-, MNI-,
    or SPM-template, or some other reference image you choose to use.
    - The source image (normally a higher resolution structural image)
    is used to calculate the transformation matrix necessary to map
    the source image onto the template image. This transformation
    matrix is then used to map the rest of your images (functional and
    structural) into the reference-space.


*** Smoothing

Structural as well as functional images are smoothed by applying a
filter to the image. Smoothing increases the signal to noise ratio of
your data by filtering the highest frequencies from the frequency
domain; that is, removing the smallest scale changes among voxels.
That helps to make the larger scale changes more apparent. There is
some inherent variability in functional location among individuals,
and smoothing helps to reduce spatial differences between subjects and
therefore aids comparing multiple subjects. The trade-off, of course,
is that you lose resolution by smoothing. Keep in mind, though, that
smoothing can cause regions that are functionally different to combine
with each other. In such cases a surface based analysis with smoothing
on the surface might be a better choice.

#+ATTR_ORG: :width 1000
[[./images/smoothed.png]]

Smoothing is implemented by applying a 3D Gaussian kernel to the
image, and the amount of smoothing is typically determined by its full
width at half maximum (FWHM) parameter. As the name implies, FWHM is
the width/diameter of the smoothing kernel at half of its height. Each
voxel’s value is changed to the result of applying this smoothing
kernel to its original value.

Choosing the size of the smoothing kernel also depends on your reason
for smoothing. If you want to study a small region, a large kernel
might smooth your data too much. The filter shouldn’t generally be
larger than the activation you’re trying to detect. Thus, the amount
of smoothing that you should use is determined partly by the question
you want to answer. Some authors suggest using twice the voxel
dimensions as a reasonable starting point.

#+ATTR_ORG: :width 400
[[./images/kernel.png]]

*** Segmentation
Segmentation is the process by which a brain is divided into
neurological sections according to a given template specification.
This can be rather general, for example, segmenting the brain into
gray matter, white matter and cerebrospinal fluid, as is done with
SPM’s Segmentation, or quite detailed, segmenting into specific
functional regions and their subregions, as is done with FreeSurfer’s
recon-all, and that is illustrated in the figure.

Segmentation can be used for different things. You can use the
segmentation to aid the normalization process or use it to aid further
analysis by using a specific segmentation as a mask or as the
definition of a specific region of interest (ROI).
#+ATTR_ORG: :width 400
[[./images/segmentation.gif]]


* Getting to know the libraries and the data

First, we import the data.

#+begin_src python
import matplotlib.pyplot as plt
import nibabel as nib # Useful to load data
import nilearn
from nilearn import datasets
from nilearn import plotting
from pathlib import Path
import dotenv
import numpy as np
import networkx as nx
import pandas as pd
from nilearn.input_data import NiftiMapsMasker
from nilearn.connectome import ConnectivityMeasure
#+end_src

Let's load an image

#+begin_src python
DOTENV_KEY2VAL = dotenv.dotenv_values()
path = "/".join([DOTENV_KEY2VAL["ROOT_DIR"], DOTENV_KEY2VAL["DATA_DIR"], "sub-ADNI002S0295/M00/sub-ADNI002S0295-MNI_brain_normalized.nii.gz"])
img = nib.load(path)
#+end_src


Now an atlas. MSDL is a probabilistic atlas
#+begin_src python
atlas = datasets.fetch_atlas_msdl()
atlas_filename = atlas["maps"]
#+end_src

For an fMRI, the pipeline goes as follows:
#+begin_src python
labels = atlas['labels']
data = datasets.fetch_development_fmri(n_subjects=1)
data = data.func[0]
masker = NiftiMapsMasker(maps_img=atlas_filename, standardize=True,
                         memory='nilearn_cache', verbose=5)

time_series = masker.fit_transform(data)
# shape is (number of time points x number of regions)

correlation_measure = ConnectivityMeasure(kind='correlation')
correlation_matrix = correlation_measure.fit_transform([time_series])[0]

np.fill_diagonal(correlation_matrix, 0)
plotting.plot_matrix(correlation_matrix, labels=labels, colorbar=True,
                     vmax=0.8, vmin=-0.8)
plotting.show()
time_series.shape
#+end_src

Results in time series dimensions:
| Time stamps | Voxels |
|         168 |     39 |

Plot fancy connectome graph

#+begin_src python
coords = atlas.region_coords
# We threshold to keep only the 20% of edges with the highest value
# because the graph is very dense
plotting.plot_connectome(correlation_matrix, coords,
                         edge_threshold="80%", colorbar=True)
plotting.show()
#+end_src

That's all super cool.

The only thing is, we don't have multiple time points per visit. We
First, we import the datahave only 1. Indeed, let us
consider one of our files with the same atlas:

#+begin_src python
time_series = masker.fit_transform(data)
# shape is (number of time points x number of regions)
print(time_series.shape)
correlation_measure = ConnectivityMeasure(kind='correlation')
correlation_matrix = correlation_measure.fit_transform([time_series])[0]

np.fill_diagonal(correlation_matrix, 0)
plotting.plot_matrix(correlation_matrix, labels=labels, colorbar=True,
                     vmax=0.8, vmin=-0.8)
plotting.show()
#+end_src

That's not working, because we have 3D. not 4D data for each visit.
The only way we could do so is to stitch together MRI images and make
the correlation matrix for _those_.

Q: what exactly does =time_series = masker.fit_transform(img)= output?
What is a masker?
From [[https://nilearn.github.io/manipulating_images/masker_objects.html][nilearn]] we get the following useful information:
"In any analysis, the first step is to load the data. It is often
convenient to apply some basic data transformations and to turn the
data in a 2D (samples x features) matrix, where the samples could be
different time points, and the features derived from different voxels
(e.g., restrict analysis to the ventral visual stream), regions of
interest (e.g., extract local signals from spheres/cubes), or
pre-specified networks (e.g., look at data from all voxels of a set of
network nodes). Think of masker objects as swiss-army knifes for
shaping the raw neuroimaging data in 3D space into the units of
observation relevant for the research questions at hand."

Specifically for =NiftiMasker=:
NiftiMasker is a powerful tool to load images and extract voxel signals in the area defined by the mask. It applies some basic preprocessing steps with commonly used parameters as defaults. *But it is very important to look at your data to see the effects of the preprocessings and validate them.*

Let us go ahead and try to stack the timeseries signals from voxels
from different time points.

#+begin_src python
masker = NiftiMapsMasker(maps_img=atlas_filename, standardize=True,
                         memory='nilearn_cache', verbose=5)

path = DOTENV_KEY2VAL["ROOT_DIR"] + DOTENV_KEY2VAL["DATA_DIR"]
patients = os.listdir(path)
patient = patients[0]
time_series = np.array([])
i=1
for root,dirs,files in os.walk(path + patient):
    for image in files:
        if "T1w" in image:
            print(image)
            img = nib.load(root + "/" + image)
            time_series_timestamp = masker.fit_transform(img)
            time_series = np.append([[time_series]], [[time_series_timestamp]])
            time_series = time_series.reshape((i,39))
            print(time_series)
            i = i + 1
#+end_src

#+RESULTS:


#+begin_src python
correlation_measure = ConnectivityMeasure(kind='correlation')
correlation_matrix = correlation_measure.fit_transform([time_series])[0]

np.fill_diagonal(correlation_matrix, 0)
plotting.plot_matrix(correlation_matrix, labels=labels, colorbar=True,
                     vmax=0.8, vmin=-0.8)
plotting.show()
#+end_src

#+begin_src python
coords = atlas.region_coords
# We threshold to keep only the 20% of edges with the highest value
# because the graph is very dense
plotting.plot_connectome(correlation_matrix, coords,
                         edge_threshold="80%", colorbar=True)
plotting.show()
#+end_src

Good, so let's make a graph out of it.
PS: we take absolute value, because negative coorelations are just as
important?

#+begin_src python
threshold = 0.8
binarized_matrix =  np.where(correlation_matrix>np.abs(threshold), 1, 0)
#+end_src

Transform into graph object

#+begin_src python
df = pd.DataFrame(data=binarized_matrix, columns=labels, index=labels)
G = nx.from_pandas_adjacency(df)
#+end_src

... Perform topological data analysis from this graph.


* Working with FSL and freesurfer
** Plan
1. FSL (Oxford Centre for Functional MRI of the Brain (FMRIB F)
  Software Library) - Brain Extraction Tool (BET)
2. Lesion Filling (manual step)
3. Freesurfer - identify brain
   regions  ~82 brain region - This
   is where we look at different atlases.
4. Freesurfer - identify brain volumes
5. So in each cell of the correlation matrix there is a number between -1
and 1 that represent the Pearson correlation coefficient between
ROI’s. The diagonal elements of the constructed correlation matrix are
set to zero.
-> These images have already been preprocessed in the provided
directory, so no need to worry about that.
