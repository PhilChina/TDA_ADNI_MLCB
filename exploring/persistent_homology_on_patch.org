#+BIND: org-export-use-babel nil
#+TITLE: Applying filtration to subsample
#+AUTHOR: Philip Hartout
#+EMAIL: <philip.hartout@protonmail.com>
#+DATE: October 18, 2020
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS:[a4paper,12pt,twoside]
#+LaTeX_HEADER:\usepackage[usenames,dvipsnames,figures]{xcolor}
#+LaTeX_HEADER:\usepackage[autostyle]{csquotes}
#+LaTeX_HEADER:\usepackage[final]{pdfpages}
#+LaTeX_HEADER:\usepackage[top=3cm, bottom=3cm, left=3cm, right=3cm]{geometry}
#+LATEX_HEADER_EXTRA:\hypersetup{colorlinks=false, linkcolor=black, citecolor=black, filecolor=black, urlcolor=black}
#+LATEX_HEADER_EXTRA:\newtheorem{definition}{Definition}[section]
#+LATEX_HEADER_EXTRA:\pagestyle{fancy}
#+LATEX_HEADER_EXTRA:\setlength{\headheight}{25pt}
#+LATEX_HEADER_EXTRA:\lhead{\textbf{Philip Hartout}}
#+LATEX_HEADER_EXTRA:\rhead{\textbf{}}
#+LATEX_HEADER_EXTRA:\rfoot{}
#+MACRO: NEWLINE @@latex:\\@@ @@html:<br>@@
#+PROPERTY: header-args :exports both :session python_emacs_session :cache :results value
#+OPTIONS: ^:nil
#+TODO: TODO IN-PROGRESS WAITING | DONE CANCELED
#+STARTUP: latexpreview
#+LATEX_COMPILER: pdflatexorg-mode restarted

Let's load the patches of images and apply the filtration to it.

Programme:


- VR filtration
- Cubical filtration
- Statistical investigation of filtration

* Imports

#+BEGIN_SRC python
import nibabel
import nibabel as nib  # Useful to load data

import nilearn
from nilearn import datasets
from nilearn.regions import RegionExtractor
from nilearn import plotting
from nilearn.image import index_img
from nilearn.plotting import find_xyz_cut_coords
from nilearn.input_data import NiftiMapsMasker
from nilearn.connectome import ConnectivityMeasure
from nilearn.regions import RegionExtractor
from nilearn import plotting
from nilearn.image import index_img
from nilearn import datasets
from nilearn import plotting

import matplotlib.pyplot as plt


from pathlib import Path
import dotenv


import numpy as np
import networkx as nx
import pandas as pd

import plotly.express as px
import plotly.graph_objects as go

import nighres

import gtda
from gtda.images import ImageToPointCloud, ErosionFiltration
from gtda.homology import VietorisRipsPersistence
from gtda.diagrams import PersistenceEntropy
from gtda.pipeline import Pipeline
from gtda.plotting import plot_diagram, plot_point_cloud, plot_heatmap
from gtda.homology import CubicalPersistence
from gtda.diagrams import (
    Scaler,
    Filtering,
    PersistenceEntropy,
    BettiCurve,
    PairwiseDistance,
)

import os
import tempfile
from urllib.request import urlretrieve
import zipfile

from sklearn.linear_model import LogisticRegression
from skimage import io
#+END_SRC

Determine threshold for pointcloud

#+BEGIN_SRC python
patch = np.load("../data/cropped/sub-ADNI002S0295-M00-MNI.npy")
patch.shape
#+END_SRC

#+BEGIN_SRC python
plt.hist(np.unique(patch),bins=100)
plt.show()
#+END_SRC

It seems that the values are bounded between 0 and 1, so take 0.5 as a
threshold. But let's look at a slide of the data.

#+BEGIN_SRC python
plt.imshow(patch[15,:])
plt.show()
#+END_SRC

* Build slicer

From [[https://www.datacamp.com/community/tutorials/matplotlib-3d-volumetric-data][this tutorial]] we want to build a slicer to determine the optimal
threshold to binarize our data for the VR persistance.

Get data for tutorial
#+BEGIN_SRC python

# Create a temporary directory
d = tempfile.mkdtemp()



# Return the tail of the path
os.path.basename('http://google.com/attention.zip')

# Define URL
url = 'http://www.fil.ion.ucl.ac.uk/spm/download/data/attention/attention.zip'

# Retrieve the data
fn, info = urlretrieve(url, os.path.join(d, 'attention.zip'))
# Extract the contents into the temporary directory we created earlier
zipfile.ZipFile(fn).extractall(path=d)

# Read the image
struct = nibabel.load(os.path.join(d, 'attention/structural/nsM00587_0002.hdr'))

# Get a plain NumPy array, without all the metadata
struct_arr = struct.get_data()
struct_arr = io.imread("https://s3.amazonaws.com/assets.datacamp.com/blog_assets/attention-mri.tif")
#+END_SRC

Plotting with the toy data

#+BEGIN_SRC python
plt.imshow(struct_arr[75])
plt.show()
#+END_SRC

Sagittal view
#+BEGIN_SRC python
plt.imshow(struct_arr[75], aspect=0.5)
plt.show()
#+END_SRC

Axial view
#+BEGIN_SRC python
struct_arr2 = struct_arr.T
plt.imshow(struct_arr2[34])
plt.show()
#+END_SRC

Coronal view
#+BEGIN_SRC python
plt.imshow(struct_arr2[5])
plt.show()
#+END_SRC


Definition of the functions used in slicer

#+BEGIN_SRC python

def multi_slice_viewer(volume):
    remove_keymap_conflicts({'j', 'k'})
    fig, ax = plt.subplots()
    ax.volume = volume
    ax.index = volume.shape[0] // 2
    ax.imshow(volume[ax.index])
    fig.canvas.mpl_connect('key_press_event', process_key)

def process_key(event):
    fig = event.canvas.figure
    ax = fig.axes[0]
    if event.key == 'j':
        previous_slice(ax)
    elif event.key == 'k':
        next_slice(ax)
    fig.canvas.draw()

def previous_slice(ax):
    volume = ax.volume
    ax.index = (ax.index - 1) % volume.shape[0]  # wrap around using %
    ax.images[0].set_array(volume[ax.index])

def next_slice(ax):
    volume = ax.volume
    ax.index = (ax.index + 1) % volume.shape[0]
    ax.images[0].set_array(volume[ax.index])

def remove_keymap_conflicts(new_keys_set):
    for prop in plt.rcParams:
        if prop.startswith('keymap.'):
            keys = plt.rcParams[prop]
            remove_list = set(keys) & new_keys_set
            for key in remove_list:
                keys.remove(key)
#+END_SRC

Slicer with toy data
#+BEGIN_SRC python

multi_slice_viewer(struct_arr2)

#+END_SRC


cleanup tmp files

#+BEGIN_SRC python
import shutil

# Remove the temporary directory
shutil.rmtree(d)
#+END_SRC

Slicer with our data
#+BEGIN_SRC python
multi_slice_viewer(patch)
plt.show()
#+END_SRC

This works! Now let's define an appropriate threshold for the data.

* Threshold definition for image binarization


Let's also get a histogram of the pixels as well
#+BEGIN_SRC python
plt.hist(patch.flatten(),bins=100)
plt.show()
#+END_SRC

#+BEGIN_SRC python
plt.hist(np.unique(patch),bins=100)
plt.show()
#+END_SRC

#+BEGIN_SRC python
binarized_patch = np.where(patch>0.25, 1, 0)
multi_slice_viewer(binarized_patch)
multi_slice_viewer(patch)
plt.show()
#+END_SRC

This works great but is there a more formal way of finding edges holes
than a hard threshold? Maybe other ways of preprocessing the data in topology?

Let's import the function to transform an image to a point cloud we first defined [[../exploring/exploring_influence_of_delineation_temporal_region_on_topological_descriptors.org][here]].

#+BEGIN_SRC python
def transform_image_to_point_cloud(img, target_shape, threshold=0):
    """Transform array to point cloud using threshold (above which there's
    a one. otherwise a 0)
    """
    binarized_image = np.where(img>threshold, 1, 0)
    binarized_image = binarized_image.reshape(target_shape)
    point_cloud_tranformer = gtda.images.ImageToPointCloud()
    point_cloud = point_cloud_tranformer.fit_transform(binarized_image)
    point_cloud_coords = np.empty(shape=(3,))
    point_cloud = np.vstack((np.asarray(point_cloud)))
    return point_cloud
#+END_SRC



#+BEGIN_SRC python
shape = (1, 30, 36, 30)
point_cloud_tranformer = gtda.images.ImageToPointCloud()
patch_pc = point_cloud_tranformer.fit_transform(binarized_patch.reshape(shape))
#+END_SRC

#+BEGIN_SRC python
df = pd.DataFrame(patch_pc[0]).rename(columns={0: "x", 1: "y", 2: "z"})

x, y, z = df["x"].values, df["y"].values, df["z"].values
fig = go.Figure("data":[go.Scatter3d(
    x=x,
    y=y,
    z=z,
    mode='markers',
    marker=dict(
         size=5,
         color=x,                # set color to an array/list of desired values
         colorscale='Viridis',   # choose a colorscale
         opacity=0.8
    )
)])

# tight layout
fig.update_layout(margin=dict(l=0, r=0, b=0), title="CN patient")
fig.show()
#+END_SRC


This seems to work now at least for one patch. Now let's look at the
topology.


#+begin_src python
homology_dimensions = (0, 1, 2)
VR = VietorisRipsPersistence(metric="euclidean", max_edge_length=5, homology_dimensions=homology_dimensions, n_jobs=8)
diagrams_VietorisRips = VR.fit_transform(np.asarray(patch_pc))
#+end_src

#+BEGIN_SRC python
VR.plot(diagrams_VietorisRips)
BC = BettiCurve()
X_betti_curves = BC.fit_transform(diagrams_VietorisRips)
BC.plot(X_betti_curves)
#+END_SRC

Let's just take a sample from AD and CN.

#+BEGIN_SRC python
patch_ad = np.load("../data/cropped/sub-ADNI002S0729-M48-MNI.npy")
patch_ad.shape
binarized_patch_ad = np.where(patch_ad>0.25, 1, 0)
#+END_SRC


#+BEGIN_SRC python
shape = (1, 30, 36, 30)
point_cloud_tranformer = gtda.images.ImageToPointCloud()
patch_ad_pc = point_cloud_tranformer.fit_transform(binarized_patch_ad.reshape(shape))
#+END_SRC


#+begin_src python
homology_dimensions = (0, 1, 2)
VR = VietorisRipsPersistence(metric="euclidean", max_edge_length=5, homology_dimensions=homology_dimensions, n_jobs=8)
diagrams_VietorisRips = VR.fit_transform(np.asarray(patch_ad_pc))
#+end_src

#+BEGIN_SRC python
VR.plot(diagrams_VietorisRips).show()
BC = BettiCurve()
X_betti_curves = BC.fit_transform(diagrams_VietorisRips)
BC.plot(X_betti_curves)
#+END_SRC

Now let's look at both *(code above bundled together to avoid mistakes)*

#+BEGIN_SRC python
multi_slice_viewer(patch_ad)
multi_slice_viewer(patch)
plt.show()
#+END_SRC

* Cleaner implementation

Make plot

First we define a bunch of functions in a utils file which might
become handy later on.
#+BEGIN_SRC python
def make_3d_scatterplot(point_cloud, title):
    df = pd.DataFrame(point_cloud).rename(columns={0: "x", 1: "y", 2: "z"})

    x, y, z = df["x"].values, df["y"].values, df["z"].values
    fig = go.Figure(
        data=[
            go.Scatter3d(
                x=x,
                y=y,
                z=z,
                mode="markers",
                marker=dict(
                    size=5,
                    color=x,  # set color to an array/list of desired values
                    colorscale="Viridis",  # choose a colorscale
                    opacity=0.8,
                ),
            )
        ]
    )

    # tight layout
    fig.update_layout(margin=dict(l=0, r=0, b=0), title=title)
    fig.show()
#+END_SRC

#+BEGIN_SRC python
make_3d_scatterplot(point_cloud, title)
make_3d_scatterplot(point_cloud, title)
#+END_SRC

VR on plots

#+BEGIN_SRC python
shape = (1, 30, 36, 30)
point_cloud_tranformer = gtda.images.ImageToPointCloud()
patch_ad_pc = point_cloud_tranformer.fit_transform(binarized_patch_ad.reshape(shape))
#+END_SRC


#+begin_src python
homology_dimensions = (0, 1, 2)
VR = VietorisRipsPersistence(metric="euclidean", max_edge_length=5, homology_dimensions=homology_dimensions, n_jobs=8)
diagrams_VietorisRips = VR.fit_transform(np.asarray(patch_ad_pc))
#+end_src

#+BEGIN_SRC python
VR.plot(diagrams_VietorisRips).show()
BC = BettiCurve()
X_betti_curves = BC.fit_transform(diagrams_VietorisRips)
BC.plot(X_betti_curves)
#+END_SRC

* Using =utils.py=

#+BEGIN_SRC python
import utils
patch_cn_binarized, patch_cn = utils.prepare_image("../data/cropped/sub-ADNI002S0295-M00-MNI.npy", 0.5)
patch_ad_binarized, patch_ad = utils.prepare_image("../data/cropped/sub-ADNI002S0729-M48-MNI.npy", 0.5)
patch_cn_pc = utils.prepare_point_cloud(patch_cn_binarized)
patch_ad_pc = utils.prepare_point_cloud(patch_ad_binarized)
utils.make_3d_scatterplot(patch_cn_pc[0], "CN patient")
utils.make_3d_scatterplot(patch_ad_pc[0], "AD patient")
utils.vr_persistent_homology(patch_cn_pc[0])
utils.vr_persistent_homology(patch_ad_pc[0])
#+END_SRC

* Cubical persistence

Let's try cubical persistence as this seems to be _de facto_ standard in
MRI images.

#+BEGIN_SRC python
import utils
patch_cn_binarized, patch_cn = utils.prepare_image("../data/cropped/sub-ADNI002S0295-M00-MNI.npy", 0.5)
patch_ad_binarized, patch_ad = utils.prepare_image("../data/cropped/sub-ADNI002S0729-M48-MNI.npy", 0.5)
utils.cubical_persistence(patch_cn)
utils.cubical_persistence(patch_ad)
#+END_SRC

* Erosion filtration
https://giotto-ai.github.io/gtda-docs/latest/modules/generated/images/gtda.images.ErosionFiltration.html

Filtrations of 2D/3D binary images based on the erosion of activated regions.

Binary erosion is a morphological operator commonly used in image processing and relies on the scipy.ndimage module.

This filtration assigns to each pixel in an image a greyscale value
calculated as follows. If the minimum Manhattan distance between the
pixel and any deactivated pixel in the image is less than or equal to
the parameter n_iterations, the assigned value is this distance – in
particular, deactivated pixels are assigned a value of 0. Otherwise,
the assigned greyscale value is the sum of the lengths along all axes
of the image – equivalently, it is the maximum Manhattan distance
between any two pixels in the image. The name of this filtration comes
from the fact that these values can be computed by iteratively eroding
activated regions, shrinking them by a total amount n_iterations.

#+BEGIN_SRC python
import utils
SHAPE = (1, 30, 36, 30)
patch_cn_binarized, patch_cn = utils.prepare_image("../data/cropped/sub-ADNI002S0295-M00-MNI.npy", 0.5)
ef = ErosionFiltration(n_iterations=1000, n_jobs=-1)
diagrams_Erosion = ef.fit_transform(patch_cn.reshape(SHAPE))
ef.plot(diagrams_Erosion, sample=0).show()
multi_slice_viewer(diagrams_Erosion.reshape((30, 36, 30)))
plt.show()
#+END_SRC


* Statistics on persistence diagrams


* Future directions.
- What if we do a filtration on the negative space? On the edge space
  (=filtration on the border between tissue and non-tissue?)
- What descriptors used diagrams?
- What if we perform the analysis on non-MNI space?
