\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
\PassOptionsToPackage{}{natbib}
% before loading neurips_2020

% ready for submission
%\usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%\usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[final]{neurips_2020}
% to avoid loading the natbib package, add option nonatbib:
\usepackage{neurips_2020}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amsmath}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{url}
\usepackage{textgreek}
\usepackage{amsfonts}
\usepackage{caption, subcaption}
\usepackage[pdftex]{graphicx}
\usepackage{tikz}
\usepackage{xcolor}

\usetikzlibrary{shapes,arrows}
\definecolor{orange}{rgb}{1,0.5,0}

\tikzstyle{orange} = [rectangle, draw, fill=orange,
    text width=7em, text centered, rounded corners]

\tikzset{
  myarrow/.style={->, >=latex', shorten >=1pt, thick},
	}

\hypersetup{
  colorlinks   = true,
  linkcolor = blue,
  anchorcolor = blue,
  citecolor = black,
  % filecolor,
  % menucolor,
  % runcolor,
  urlcolor = cyan,
  % allcolors = black,
}

\title{Uncovering the topology of the medial temporal lobe in Alzheimer's disease.}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{Philip Hartout\thanks{With thanks to Bastian Rieck for the supervision and Sarah
  Brueningk, Felix Hensel, Catherine Jutzeler, Merel Kuijs, and Louis Lukas for insightful discussions, code, and data. Last compiled: \today}\\ Department of Biosystems Science and Engineering\\ ETH Zürich\\ Zürich, Switzerland \\ \texttt{phartout@ethz.ch} \\ } \date{\today}

\begin{document}

\maketitle

\begin{abstract}
Topological data analysis on medical imaging data is an emerging field leveraging the shape of data
for various application domains, including machine learning tasks. Here, we apply a topological data
analysis pipeline to uncover novel insights in the Alzheimer's disease neuroimaging initiative
dataset by applying persistent homology on a patch of the medial temporal lobe to extract
persistence images and persistence landscapes. We use these representations to (i) learn to classify
patients suffering from Alzheimer's disease from cognitively normal patients thereby assessing the
saliency of persistence images extracted from the most affected brain regions in Alzheimer's
disease, (ii) analyze the topological heterogeneity of each of the diagnostic categories, as well as
(iii) across various time points available for each patient. Finally, we use these representations
to (iv) cluster the patients according to their diagnosis and disease subtypes, when applicable.
\end{abstract}

A graphical abstract of the analyses discussed in this report is shown in
Figure~\ref{fig:graphical_abstract}

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[align=center, node distance = 1cm, auto]
    \node[](unprocessed) {\includegraphics[width=0.15\textwidth]{figures/t1_unprocessed.jpg}};
    \node[below of=unprocessed, yshift=-0.3cm](unprocessed_txt){Unprocessed};

    \node[right of=unprocessed, xshift=2.5cm](processed)
         {\includegraphics[width=0.15\textwidth]{figures/T1_BET.png}}; \node[below of=processed,
           yshift=-0.3cm](processed_txt) {\textit{fMRIPrep}};
         \draw[myarrow](unprocessed.east)--(processed.west);

    \node[right of=processed, xshift=2.5cm](selection)
         {\includegraphics[width=0.15\textwidth]{figures/patch_performance.png}}; \node[below
           of=selection, yshift=-0.3cm](selection_txt) {Patch selection};
         \draw[myarrow](processed.east)--(selection.west);

    \node[right of=selection, xshift=2.5cm](persistence_homology)
         {\includegraphics[width=0.15\textwidth]{figures/PDs/persistence_diagram_CN.png}};
         \node[below of=persistence_homology, yshift=-0.3cm](persistence_homology_txt) {Persistence
           homology}; \draw[myarrow](selection.east)--(persistence_homology.west);

    \node[below of=selection_txt, yshift=-1.3cm](persistence_image)
         {\includegraphics[width=0.15\textwidth]{figures/representative_samples/Persistence_image_CN_h_1.png}};
         \node[below of=persistence_image, yshift=-0.3cm](persistence_image_txt) {Persistence
           image}; \draw[myarrow](persistence_homology_txt.south)--(persistence_image.north);

    \node[left of=persistence_image, xshift=-2.5cm](classification)
         {\includegraphics[width=0.15\textwidth]{figures/neuralnetwork.png}}; \node[below
           of=classification, yshift=-0.3cm](classification_txt) {Classification};
         \draw[myarrow](persistence_image.west)--(classification.east);

    \node[left of=classification, xshift=-2.5cm](misclassified)
         {\includegraphics[width=0.15\textwidth]{figures/misclassified.png}}; \node[below
           of=misclassified, yshift=-0.3cm](misclassified_txt) {Misclassified samples\\ analysis};
         \draw[myarrow](classification.west)--(misclassified.east);

    \node[right of=persistence_image, xshift=2.5cm](persistence_landscape)
         {\includegraphics[width=0.15\textwidth]{figures/Persistence_landscape_CN.png}}; \node[below
           of=persistence_landscape, yshift=-0.3cm](persistence_landscape_txt) {Persistence
           landscape};
         \draw[myarrow](persistence_homology_txt.south)--(persistence_landscape.north);

    \node[below of=persistence_landscape_txt, yshift=-1.6cm](median_persistence_landscape)
    {\includegraphics[width=0.15\textwidth]{figures/median_pls/median_pl_CN_rep.png}};
         \node[below of=median_persistence_landscape,
           yshift=-0.3cm](median_persistence_landscape_txt) {Median persistence \\landscape and
           image};
         \draw[myarrow](persistence_landscape_txt.south)--(median_persistence_landscape.north);
         \draw[myarrow](persistence_image_txt.south)--(median_persistence_landscape.north);

    \node[left of=median_persistence_landscape, xshift=-2.5cm](distance_analysis)
    {\includegraphics[width=0.15\textwidth]{figures/median_pis/median_pi_CN_H_0_displot.png}};
         \node[below of=distance_analysis, yshift=-0.3cm](distance_analysis_txt) {Distance
           analysis}; \draw[myarrow](median_persistence_landscape.west)--(distance_analysis.east);
         %\draw[myarrow](misclassified_txt.south)--(distance_analysis.north);

    \node[left of=distance_analysis, xshift=-2.5cm](clustering)
         {\includegraphics[width=0.15\textwidth]{figures/clustering.png}}; \node[below
           of=clustering, yshift=-0.3cm](clustering_txt) {Visualisation of distance \\to two median
           images}; \draw[myarrow](distance_analysis.west)--(clustering.east);

  \end{tikzpicture}
  \caption{Flow chart of the analyses conducted in this report. Images adapted from
    \href{https://commons.wikimedia.org/wiki/Brain/media/File:MRI_head_side.jpg}{Wikimedia},
    \href{https://www.slicer.org/wiki/Documentation/Nightly/Modules/BrainVolumeRefinement}{
      slicer.org}, \href{https://thenounproject.com/xela./collection/diagrams/?i=486221}{Xela Ub}
    and \href{https://thenounproject.com/smodgekar/collection/data-classify/}{Sachin Modgekar}}
\label{fig:graphical_abstract}
\end{figure}

\section{Introduction}

\subsection{Alzheimer's disease}\label{sec:ad_context}

Alzheimer's disease (AD) is the most prevalent form of dementia in the world, with a forecasted 75
million cases in 2030 and 132 million by 2050 \citep{world2017global}. In EU member states and
Switzerland, AD is already among the leading causes of death and is projected to further accelerate
in the future \citep{sleeman2019escalating}. The associated costs are immense---in the United
States alone, the cost of care of AD patients is expected to be \$2 trillion by 2030---, and are
poised to substantially burden the economic prosperity of developed countries in the future
~\citep{world2017global}. Although the definite diagnosis of a patient with AD can only be done
post-mortem, clinicians use a plethora of standardized tools to find indications of the developing
pathology as early as possible, ranging from neuropsychological tests, blood and cerebrospinal fluid
biomarkers, to MRI images ~\citep{mckhann2011diagnosis, smits2012early, lehmann2016biomarkers}.

Although there are disputes on the root cause of the disease in the late-onset form of AD
\citep{tharp2013origins, fulop2018can, hur2020innate}, there is a wide consensus that the presence
of Amyloid \textbeta{} (A\textbeta{}), originating from cleavage of the amyloid precursor protein
(APP), together with the aggregation of neurofibrillary tangles, stemming from hyperphosphorylated
tau proteins, accumulate in the brain of patients with AD and leads to neural cell death
~\citep{da2016insights}. This cellular destruction leads to a cumulative effect: brain atrophy,
which refers to the shrinkage of brain volume. This damage particularly affects brain regions
involved in memory formation such as the medial temporal lobe (MTL), which contains the entorhinal
cortex, the hippocampus, and the amygdala is visible using structural Magnetic Resonance Imaging
(sMRI) ~\citep{frisoni2010clinical, goedert2006century}, and has been heralded as one of the most
reliable biomarkers for Alzheimer's disease \citep{pini2016brain}.

Such images provide a rich source of data, which can then be used for various purposes. One of them
is classification, which consists of categorizing cognitively intact subjects (CN) and AD patients
using deep learning techniques such as convolutional neural networks ~\citep{wen2020convolutional}.
Additionally, sMRI data can be used to identify multiple regions affected by the disease, and
patterns have emerged as to which groups of regions are affected, leading to the definition of
various subtypes of AD ~\citep{poulakis2018heterogeneous,tijms2020pathophysiological}. To gain even
finer insights from the observable alterations of brain shape in the context of AD with minimal
computation, ideas stemming from the mathematical field of topology can be applied. Topology
concerns itself with properties of geometric objects under continuous deformations, such as
stretching, twisting, crumpling, and bending. Such deformations aptly summarize the type of
deformation occurring to the brain due to AD and therefore makes an ideal context in which we can
apply computational topology to uncover and quantify anatomical changes resulting from the disease.

\subsection{Topology}

Topology has witnessed relentless theoretical progress since Henri Poincaré first addressed
topological ideas as a distinct branch of mathematics in his 1895 publication of \textit{Analysis
Situs}~\citep{poincare1895analysis, james1999history}. Only recently, -- with the advent of modern
computing -- has the field of computational topology and topological data analysis (TDA) gained
momentum to investigate (high-dimensional) data in physics, biology, and
beyond~\citep{dey1999computational, ghrist2008barcodes, amezquita2020shape}. While surveying the
various applications of computational topology are beyond the scope of this report, we still want to
define several procedures that are paramount to the workflow described in this report: cubical
persistence, various vectorized representations of the persistence diagrams obtained from filtered
cubical complexes, and the notion of pairwise distance between such representations. For material
providing an extensive and formal introduction to topology and persistent homology, please refer
to~\citet{freedman2009algebraic, edelsbrunner2010computational}, and \citet{ghrist2008barcodes}.


\subsubsection{Cubical complexes and persistent homology}

Before defining the notion of cubical persistence, \emph{cubical complexes} need to be defined. For
that, let us first assign to each elementary non-degenerate interval for some $[a,a+1]\forall
a\in\mathbb{R}$, two degenerate intervals $[a,a]$ and $[a+1,a+1]$. For a
$d$-dimensional space, a cube is then defined as a product of $d$ elementary intervals
$\Pi_{i=1}^{d}I_i$. The dimension of the cube is then equal to the number of non-degenerate interval
in the aforementioned product, such that 0-cubes, 1-cubes, 2-cubes, and 3-cubes correspond to
vertices, edges, squares, and 3D cubes, respectively. In this report, the 3D cube corresponds to a
given voxel--- or 3d pixel---of our sMRI.

A cubical complex $X$ of dimension $d$ is then defined as a finite set of elementary cubes of at
most dimension $d$, where $X$ must be closed undertaking faces and intersections. This means that
for any cube in $X$, all of its faces must belong to $X$, and for any two cubes in $X$, their
intersection is either empty, or there is a common face between them.

To obtain the cubical complex $\mathbb{X}$ contained in an sMRI image of a particular patient
taken at a particular timepoint, we use a filtering function $f:\mathbb{X}\to\mathbb{R}$, which
ranges over all pixel intensity values observed (here, these range between $0$ and $1$), to study
the topology of the sublevel sets $\mathbb{X}_t=f^{-1}(-\infty, t]$ of cubical complexes that
arise. This is a method to study topological spaces referred to as \emph{persistent homology}. A
common representation of the evolution of topological complexes as a function of the value of the
filtration function is the \emph{persistence diagram} (PD), which is a multiset of points. For each
homological dimension (here, $0,1,2$), we obtain a collection of points, with an associated $x$ and
$y$ coordinate which corresponds to the birth and death of a topological feature in the homology
dimension $n=0,1,2$. The points in homological dimensions $0,1,2$ can be interpreted as
connected components, tunnels, and cubes, respectively. We refer to a homological feature as
\emph{persistent} if the difference between its birth and death value is particularly high.


\subsubsection{Persistence images and persistence
  landscapes}\label{sec:theory_persistence_landscape_persistence_image}

PDs are endowed with a metric (further discussed in Section
\ref{sec:pairwise_distance_definitions}), so it is possible to perform a variety of machine learning
(ML) techniques using representations of PDs as input data. However, multiple ML algorithms
require more than a metric ---fixed-size vectors are often required---. It is therefore
desirable to have a fixed-length, stable, efficient-to-compute, interpretable (with respect to the
PD) and tunable mapping from the PD to a vector space in $\mathbb{R}^n$ to fit various machine
learning algorithms to them.

One such representation is the \emph{persistence image} (PI) of a PD, which has also been proven to
be stable upon small perturbations of data while still retaining the underlying features in the data
useful for classification. Computing the PI from a PD $D$ consists of a two-step process. First, the
PD is mapped to an integrable function $\rho_D : \mathbb{R}^2\to \mathbb{R}$ called a persistent
surface. This surface is a weighted sum of Gaussian distributions, each centered around a point of
the PD. The matrix of pixel values can be obtained from the computation of the integration of
$\rho_D$ on a grid overlaid on the surface ~\citep{adams2017persistence}. An overview of the
pipeline to obtain persistence images is shown in Figure~\ref{fig:pipeline_persistence_image}.

\begin{figure}[htb]
  \begin{centering}
    \includegraphics[width=1.0\textwidth]{figures/cartoon.pdf}
    \caption{Pipeline to obtain the persistence image, as presented by~\citet{adams2017persistence}.}
    \label{fig:pipeline_persistence_image}
  \end{centering}
\end{figure}

Another representation associated to the PD is the persistence landscape (PL). Similarly to PIs, PLs
maps the PD into a Hilbert space, which is useful for ML applications, but additionally
extracts the most persistent features from the PD. In order to define a persistence landscape, let
us take a pair $(b,d)$, which refer to the birth and death of a topological feature. We now define
the piecewise linear function $f_{(b,d)}:\mathbb{R} \to [0, \infty]$ as:
\begin{equation}
  \label{eq:piecewise_linear_landscape}
  f_{(b,d)}(x)=
  \begin{cases}
    0 & \text{if }x \notin (b,d)\\ x-b & \text{if }x\in (b,{b+d\over 2}]\\ -x+b & \text{if }x\in
      ({b+d\over 2},d]
  \end{cases}
\end{equation}


The PL of the birth-death pairs $\left\{b_i,d_i\right\}_{i=1}^{n}$ is the sequence of functions
$\lambda_k:\mathbb{R}\to [0,\infty]$, $k=1,2,3,\ldots$ where $\lambda_k(x)$ is the $k^{th}$ largest
value of $\left\{f_{b_i, d_i}(x)\right\}^{n}_{i=1}$. We set $\lambda_k(x)=0$ if the $k^{th}$ largest
value does not exist, which results in $\lambda_k=0$ for $k>n$ ~\citep{bubenik2015statistical,
  bubenik2020persistence}. An example of PL is shown in figure~\ref{fig:pl_bubenik}.

\begin{figure}[htb]
  \centering
  \begin{minipage}{60mm}
    \includegraphics[width=43mm]{figures/persistence_landscape_bubenik_paper/landscapes-figure7.pdf} %     \vspace{1ex}
    \includegraphics[width=53mm]{figures/persistence_landscape_bubenik_paper/landscapes-figure9.pdf}
  \end{minipage}
  \begin{minipage}{60mm}
    \vspace{5ex}
    \includegraphics[width=53mm]{figures/persistence_landscape_bubenik_paper/landscapes-figure8.pdf} %     \vspace{-5ex}
    \includegraphics[width=53mm]{figures/persistence_landscape_bubenik_paper/paper3dlandscape.png}
  \end{minipage}
  \vspace{5ex}
  \caption{PL for the homology in degree 1 of linked annuli from \citet{bubenik2015statistical}. Top
    left, persistence diagram, top right, rescaled function from equation
    \ref{eq:piecewise_linear_landscape}. Bottom left and right, 2 and 3-d representation of the
    persistent landscape. Note that $\lambda_1$ represents the most persistent topological features.}
  \label{fig:pl_bubenik}
\end{figure}

\subsubsection{Pairwise distances and medians}\label{sec:pairwise_distance_definitions}

A crucial element in our investigations consists of examining distances between vectorized
topological representations. Intuitively, and as noted by \citet{berwald2018computing}, it important
to take the meaning of the points of the PD into account; namely that a point close to the diagonal
$(c,c+\epsilon)$ represents a feature that lived for a short time $\epsilon$. A diagram with this
small lifetime point should therefore be close to the same diagram without that point, where the
feature would not appear at all. Hence, it makes sense to introduce the notion of minimal cost
required to match up points of the two diagrams, either off-diagonal to off-diagonal, or
off-diagonal to the nearest point on the diagonal (for small values of $\epsilon$). In this context,
distance functions usually applied to evaluate the distance between two probability density
distributions are relevant: the bottleneck distance and the (more general) $p$-Wasserstein distance,
where $p\geq 1$. The $p$-Wasserstein distance between two diagrams $D_1$ and $D_2$ is the infimum
over all bijections $\gamma: D_1 \cup \Delta \to D_2 \cup \Delta$, where $\Delta$ is the multiset
$\lbrace (s, s) \mid s \in \mathbb{R} \rbrace$ with multiplicity $(s,s) \mapsto +\infty$, such that:
\begin{equation}
  \label{eq:wasserstein_distance}
  W_p(D_1,D_2)=\left(\sum_{x \in D_1 \cup \Delta} ||x - \gamma(x)||_q^p \right)^{1/p}
\end{equation}

where we usually have $q=\infty$. When we let $p\to\infty$, we recover the bottleneck distance.

We also use the notion of a median persistence landscape, where, given a collection of PDs, we
compute their associated binned PL, which is a matrix of fixed dimension $m\times h$ where $m$ is
the length of the binned $\lambda_1$ persistence landscape, and $h$ is the homology dimension. We
compute the median PL by taking the median over all samples for each cell in $m$ for each homology
dimension $h$, which results in a PL representative of the collection of the samples in the
collection. A similar approach can be adopted for PIs. The median PL and PI were chosen over the
average PL or PI due to the skewed distribution of the data observed in some cases, as will be
highlighted in section \ref{sec:disc-dist}.

Taking the distance between any two persistence landscapes or images can be achieved using the
Minkowski distance, which is essentially a proxy for the $p$-Wasserstein distance for two vectors of
the same length. We define the Minkowski distance given two vectors
$\mathbf{x},\mathbf{y}\in\mathbb{R}^n$, as:
\begin{equation}
  \label{eq:minkowski}
  D(\mathbf{x},\mathbf{y}) = \left(\sum_{i=1}^{n}|x_i-y_i|^p\right)^{1\over p}.
\end{equation}

In this report, we set $p=1$ and henceforth refer to the distance function as the $L^1$ norm.

\subsection{Research questions and outline}

In this report, we address the following research questions:

\begin{enumerate}
\item How salient are the topological features extracted from the patch for the characterization of
  the atrophy observed in Alzheimer's disease as measured through the classification performance of
AD versus CN subjects using persistence images?
\item What does the distance between the persistence image and persistence
landscape of a patient and the median persistence image or landscape of a
diagnostic category reveal about the topological heterogeneity within a given
diagnostic category?
\item How can the distance among persistent images taken for each patient over the course of the
  disease inform us with regard to the progression of the patient during the monitoring period?
\item Does taking the distance between each image and two median persistence
images (from AD patients and CN subjects) allow adequate clustering of patients
in diagnostic categories or disease subtypes?
\end{enumerate}

This report is structured as follows: after having introduced AD and fundamental concepts related to
TDA in this introduction, we go on to present and justify methodological choices we have made
regarding the topological data analysis conducted on sMRI data in section \ref{sec:methods}; in
section \ref{sec:results}, we report the findings extracted from the data, which we discuss in
section \ref{sec:discussion}.

\section{Methods}\label{sec:methods}

Here, we present the methodological choices made for this pipeline. All of the code used to compute
the findings presented in this paper is currently available upon request on
\href{https://github.com/BorgwardtLab/ADNI_MRI_Analysis}{GitHub}.

\subsection{Data}

T1-weighted, 1.5 Tesla sMRIs were obtained from the \href{adni.loni.usc.edu}{Alzheimer's Disease
  Neuroimaging Initiative} (ADNI) database which contains images from AD patients, patients
diagnosed with mild cognitive impairment (MCI) \citep{gauthier2006mild}, and healthy controls
(cognitively normal, CN) of matched age groups \citep{jack2008alzheimer}. Further preprocessing
steps to reduce noise and extract brains structures is highlighted in appendix
\ref{apd:preprocessing}. Then, scans were divided into 216 patches, each of dimension
$30\times36\times30$, providing a possibility for a more focused and computationally efficient
investigation while preserving high resolution. Working with a patch is also supported by the fact
that an investigation of \emph{local} changes in brain architecture may filter out topological
features that are less relevant in the context of Alzheimer's disease.

From earlier work attempting to classify CN subjects from AD patients using a convolutional neural
network (CNN) \citep{bruningk2020image}, we know that a given patch, shown in grey in figure
~\ref{fig:acc}, has a particularly high discriminatory potential, so we selected this patch for all
our further analyses. Support for the use of this patch also comes from its anatomical relevance,
since it contains regions that are most affected in Alzheimer's disease such as the
hippocampus, the entorhinal cortex, and the amygdala ~\citep{goedert2006century}.

\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/perf_coronal.png}
    \caption{Coronal view of the selected patch.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/perf_saggital.png}
    \caption{Saggital view of the selected patch.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/perf_ventral.png}
    \caption{Ventral view of the selected patch.}
  \end{subfigure}
  \caption{Accuracy values on each patch. The selected patch is boxed in red.}
  \label{fig:acc}
\end{figure}

\subsection{Topological Data Analysis}\label{sec:tda_setup}

To perform the topological analysis on the patch, we used \texttt{giotto-tda}, a library
specifically made for the integration of TDA pipelines in ML applications
~\citep{tauzin2020giottotda}. Each filtration on the cubical complexes has been done in three
homological dimensions $0,1,2$, representing features in each of the dimensions of the
three-dimensional image. We otherwise used the default parameters provided by the
\href{https://giotto-ai.github.io/gtda-docs/latest/modules/generated/homology/gtda.homology.CubicalPersistence.html#id2}{giotto-tda
documentation}. An example persistence diagram for a cognitively intact subject, a patient with MCI,
and a patient with AD are depicted in Figure \ref{fig:sample_rep_pd}. To obtain persistence images
for each 3D volume, we used 0.001 as a standard deviation for the Gaussian kernel, no weight
function, and a default dimension of $100 \times 100$ for each image. The stability of the
performance of the classifier shown below was the highest at these particular values, although image
dimensions did not really influence the performance of local patches, however higher values for the
standard deviation of the Gaussian kernel seemed to affect performance at a value higher than 0.1.
Representative samples of these images are shown in Figure \ref{fig:sample_rep_pi}.

\begin{figure}[htb]
  \centering
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/PDs/persistence_diagram_CN_H_0.png}
    \caption{PD of a CN patient in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/PDs/persistence_diagram_MCI_H_0.png}
    \caption{PD of a MCI patient in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/PDs/persistence_diagram_AD_H_0.png}
    \caption{PD of an AD patient in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/PDs/persistence_diagram_CN_H_1.png}
    \caption{PD of a CN patient in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/PDs/persistence_diagram_MCI_H_1.png}
    \caption{PD of a MCI patient in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/PDs/persistence_diagram_AD_H_1.png}
    \caption{PD of an AD patient in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/PDs/persistence_diagram_CN_H_2.png}
    \caption{PD of an CN patient in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/PDs/persistence_diagram_MCI_H_2.png}
    \caption{PD of an MCI patient in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/PDs/persistence_diagram_AD_H_2.png}
    \caption{PD of an AD patient in $H_2$}
  \end{subfigure}
  \caption{Representative PD for each of the diagnostic categories.}
  \label{fig:sample_rep_pd}
\end{figure}


\subsection{Model architecture}\label{sec:model_arch}
For the classification task of classifying AD vs CN patients, we used a parallel CNN network with
one convolutional layer, followed by one dense layer containing 500 neurons and with dropout rates
of 50\% at training time. The output of the last dense layer is redirected to a single sigmoid
neuron for prediction. The model was trained using an exponential decay learning rate scheduler and
early stopping, which monitored the validation loss. All of the layers and utilities to train the
neural network were provided by the Keras library ~\citep{chollet2015keras} and are available on the
\href{https://github.com/BorgwardtLab/ADNI_MRI_Analysis}{repository}, and a depiction of the computation
graph is shown in Figure ~\ref{fig:model_arch}. We also note that the model was trained on a laptop
CPU (Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz). For consistency and to enable a direct comparison
with results shown in \citep{bruningk2020image}, we used the same data partitioning to present any
kind of data leakage that would artificially increase our score, as discussed in
\citet{wen2020convolutional}. We also computed persistence images with the same parameters from the
entire brain in scan projected in MNI space and trained a separate network with the same parameters.
Each model was trained three times to mitigate any performance fluctuations due to different layer
initializations.


\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[align=center, node distance = 1cm, auto]
    \node[orange, text width=12em](input){\scriptsize Persistence image ($H_0$, $H_1$, $H_2$)};
    \node[orange, below left of=input, xshift=-2.5cm,yshift=-0.25cm](conv1){\scriptsize Conv2D on $H_0$};
    \draw[myarrow](input.west)-|(conv1.north);
    \node[orange, below of=input, yshift=-0.25cm](conv2){\scriptsize Conv2D on $H_1$};
    \draw[myarrow](input.south)--(conv2.north);
    \node[orange, below right of=input, xshift=2.5cm,yshift=-0.25cm](conv3){\scriptsize Conv2D on $H_2$};
    \draw[myarrow](input.east)-|(conv3.north);
    \node[orange, below of=conv1, yshift=-0.25cm](batchmax1){\scriptsize Max pooling};
    \draw[myarrow](conv1.south)--(batchmax1.north);
    \node[orange, below of=conv2, yshift=-0.25cm](batchmax2){\scriptsize Max pooling};
    \draw[myarrow](conv2.south)--(batchmax2.north);
    \node[orange, below of=conv3, yshift=-0.25cm](batchmax3){\scriptsize Max pooling};
    \draw[myarrow](conv3.south)--(batchmax3.north);
    \node[orange, below of=batchmax2, yshift=-0.25cm](dense){\scriptsize Dense layer};
    \draw[myarrow](batchmax1.south)--(dense.west);
    \draw[myarrow](batchmax2.south)--(dense.north);
    \draw[myarrow](batchmax3.south)--(dense.east);
    \node[orange, below of=dense, yshift=-0.25cm](sigm){\scriptsize Sigmoid};
    \draw[myarrow](dense.south)--(sigm.north);
  \end{tikzpicture}

  \vspace{2cm}

  \includegraphics[width=0.9\textwidth]{figures/model.png}
  \caption{Computation graph to predict the phenotype of a given set of
    persistent images derived from applying persistent homology to an sMRI
    image. The top diagram is a simplified representation of the output of the Keras
    \texttt{plot\_model()} function, shown below.}
  \label{fig:model_arch}
\end{figure}

\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/representative_samples/Persistence_image_CN_h_0.png}
    \caption{PI of a CN patient in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/representative_samples/Persistence_image_MCI_h_0.png}
    \caption{PI of a MCI patient in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/representative_samples/Persistence_image_AD_h_0.png}
    \caption{PI of an AD patient in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/representative_samples/Persistence_image_CN_h_1.png}
    \caption{PI of a CN patient in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/representative_samples/Persistence_image_MCI_h_1.png}
    \caption{PI of a MCI patient in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/representative_samples/Persistence_image_AD_h_1.png}
    \caption{PI of an AD patient in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/representative_samples/Persistence_image_CN_h_2.png}
    \caption{PI of an CN patient in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/representative_samples/Persistence_image_MCI_h_2.png}
    \caption{PI of an MCI patient in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/representative_samples/Persistence_image_AD_h_2.png}
    \caption{PI of an AD patient in $H_2$}
  \end{subfigure}
  \caption{Representative PI for each of the diagnostic categories. Each column correponds to a
    diagnostic category whereas each row corresponds to a homological dimension.}
  \label{fig:sample_rep_pi}
\end{figure}

\subsection{Distance between median topological representations}

We also used \texttt{giotto-tda} to compute persistence landscapes. We wanted to keep only the most
prominent features, so we kept only $\lambda_1$, and set the PL vector lengths of 100. The
median PL for each homological dimension is shown in Figure~\ref{fig:median_pls}.

Computing the median persistence landscape for each diagnostic category was done using the median
value of each subject for each of the vector coordinate. The pairwise distance between two PLs was
taken using the $L^1$ norm.

We compute the distances in two settings:
\begin{description}
\item[Intra-diagnostic category setting]: here, we compute the distance of each PL available for all
available sMRIs belonging to a diagnostic category with respect to the median PL of that category.
For this particular analysis, we extracted the earliest available image for that patient so that no
redundant information is contained in the resulting distance distribution. Additionally, we check
whether or not the distribution of the distances is skewed by performing a Shapiro-Wilk test of
normality \citep{shapiro1965analysis}. A significant $p$-value--- defined at $\alpha<0.05$ for all
statistical tests used throughout this report--- for this test indicates evidence that the
distribution is not normal, therefore indicating skewness.

\item[Intra-patient distance]: this allows us to assess the distance of the different PDs of the
same patient, to see if there is any distinctive evolution of the topological features over time. In
this context, we compute the pairwise distances for all sMRIs from a patient. For some analyses, we
averaged the pairwise distance for each patient, and grouped patients that changed diagnosis over
time in one category, and those that did not in another. Additionally, the unpaired Mann-Whitney
$\mathcal{U}$ test was used to test whether the distributions of distance values depending on
whether or not the patient changed diagnosis over the course of the time images were taken stem from
the same latent distribution \citep{mann1947test}.
\end{description}

We performed each of the analyses on both persistence landscapes and images to highlight differences
among persistent features in the case of the persistence landscapes and all of the topological
features in the case of the persistence image.

\subsection{Relationship between distances and misclassification}\label{sec:relationship_distance_misclassification}

To investigate the relationship between patients departing significantly from the median
representation of the diagnostic category to which they belong and misclassified patients, we chose
to take the $n$ subjects -- hereafter referred to as \emph{topological outliers} -- with the highest
$L_1$ norm from their median representation, and set $n$ to the number of misclassified patients
from one trained network defined in section \ref{sec:model_arch} -- here, 145 images were
misclassified\footnote{Therefore, the PLs or PIs of patients with the 145 highest distance from
their respective median PL or PL.}. We then looked at the overlap between patients who were
misclassified and the selected set of topological outliers, as well as the distribution of the
distance of the misclassified samples compared to the median representation.

\subsection{Clustering using multiple median topological representations}\label{sec:methods_dist_multiple_images}

As the last step, we investigated whether the distance of a patient with respect to more than one
median persistence image efficiently differentiates between images. We, therefore, evaluated the
$L^1$ norm between each persistence image and both the median AD persistence image and median CN
persistence image in $H_2$ (i.e. voids). We chose to take these two images because they showed high
variability in other analyses (see Figure \ref{fig:displots_median_pi}) and they represent the two
most divergent diagnostic cases in our dataset, MCI being considered as a state where patients are
neither cognitively normal nor formally diagnosed with AD. Given we wanted to maximize variance
across samples for visualization purposes, we first standardized the data and subsequently applied a
principal component analysis to the resulting pairs of distances. We also compared this approach
with a metric multidimensional scaling (mMDS) plot frequently used for similar purposes.

\section{Results}\label{sec:results}

Here we present the results obtained from the above-mentioned pipeline, starting with a performance
assessment of the deep learning model. We then turn our attention to the topological heterogeneity
observed both within each diagnostic category and within each patient. We then present our findings
of the overlap between topological outliers and misclassified samples. Finally, we look at the
distance of each image to the median image representation of AD and CN to see if clusters
emerge.

\subsection{Model Performance}

The performance metrics of the deep learning model is shown in Table ~\ref{tab:performance}, and
seems to be somewhat inferior to state-of-the-art models trained on similar data
\citep{wen2020convolutional}, but requires dramatically less computing power -- the relatively
shallow multilayer CNN shown in \citet{bruningk2020image}, for instance, requires 15 minutes of
training time on a server GPU while our approach requires only 2 minutes on one laptop CPU, showing
the high grade of compression of the approach presented here. The performance measures also show
that training the same architecture on whole-brain CNNs does not yield better performance, instead
showing a slight decline. Additionally, the model trained on local PIs yields higher performance
compared to whole-brain persistence images reported in \citep{bruningk2020image} as well as when
training the network on whole-brain PIs obtained with the same parameters. Remarkably, we observe
that the performance of our network seems to be more stable than other approaches for which standard
deviations of performance metrics are provided.

\begin{table}
  \centering
  \begin{tabular}{lccccc}
    \toprule
    Local (single patch) & \textbf{PI} & & 3D Conv & & \\
    Global (whole-brain) &&\textbf{PI}& & PI & SOTA \\ \midrule Validation
    accuracy & $0.80\pm 0.02$ & $0.74\pm 0.03$ & $0.85\pm 0.06$ & $ 0.76\pm 0.02$ & $0.91$\\
    Precision & $0.81\pm 0.04$ & $0.80\pm0.05$ &  $0.78\pm 0.04$ & $0.87\pm0.04$ & - \\
    Recall & $0.81\pm 0.02$ & $0.85\pm0.08$ & $0.87\pm0.08$ & $0.88\pm 0.08$ &$0.84$\\
    AUC & $0.85\pm 0.03$ & $0.77\pm0.03$ & $0.89\pm0.05$ & $ 0.78\pm 0.02$ & $0.96$\\
    \bottomrule
    \vspace{1pt}
  \end{tabular}
  \caption{Performance metrics of the local PI approach. Bold column headers represent performance
    numbers obtained from the networks trained in this report. Global PI and local 3D Conv approach as reported from
    \citet{bruningk2020image}. SOTA results are obtained from \citet{liu2018anatomical}.}
  \label{tab:performance}
\end{table}

\subsection{Distance analysis}

\subsubsection{$L^1$ norm among diagnostic categories -- topological
  heterogeneity of each diagnostic category}\label{sec:results_between_images}

We now present our findings regarding the distribution of the distances between the PL and PI of
each image with respect to the median PL and PI for each diagnostic category. The representative PL
and PI for each diagnostic category is shown in Figure \ref{fig:median_pls} and
\ref{fig:median_pis}, and the distribution of the $L^1$ norm between each patient and these median
PLs and PIs is shown in Figure \ref{fig:displots_median_pl} and Figure \ref{fig:displots_median_pi},
respectively. Before looking at the distribution of distance values, we first note that the height
of the peak median PL of AD patients in $H_2$ seems to be \emph{lower} than in CN or MCI.
Interestingly, we see that the distribution of distances between PLs and the median PL in each
diagnostic category and homological dimension is far more skewed---which is reflected by very low
$p$-values of the Shapiro-Wilk test. For persistence images---see Figure
\ref{fig:displots_median_pi}---, the distance distributions seem to be much more homogeneous with
$p$-values still significant for some scenarios, but not all. Refer to Table
\ref{tab:stats_median_pl} for details. Overall, the $p$-values are much more closer to the
significance threshold.

\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_CN_rep.png}
    \caption{Median PL for CN subjects}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_MCI_rep.png}
    \caption{Median PL for MCI subjects}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_AD_rep.png}
    \caption{Median PL for AD subjects}
  \end{subfigure}
  \caption{Median persistence landscapes for each of the diagnostic categories.}
  \label{fig:median_pls}
\end{figure}

\begin{figure}[htb]
  \centering \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_CN_h_0_rep.png}
    \caption{Median CN PI in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_MCI_h_0_rep.png}
    \caption{Median MCI PI in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_AD_h_0_rep.png}
    \caption{Median AD PI in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_CN_h_1_rep.png}
    \caption{Median CN PI in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_MCI_h_1_rep.png}
    \caption{Median MCI PI in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_AD_h_1_rep.png}
    \caption{Median AD PI in $H_1 $}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_CN_h_2_rep.png}
    \caption{Median CN PI in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_MCI_h_2_rep.png}
    \caption{Median MCI PI in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_AD_h_2_rep.png}
    \caption{Median AD PI in $H_2$}
  \end{subfigure}
  \caption{Median persistence images for each of the diagnostic categories and homological
    dimension.}
  \label{fig:median_pis}
\end{figure}

\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_CN_H_0_displot.png}
    \caption{$L^1$ norm for CN PLs in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_MCI_H_0_displot.png}
    \caption{$L^1$ norm for MCI PLs in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_AD_H_0_displot.png}
    \caption{$L^1$ norm for AD PLs in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_CN_H_1_displot.png}
    \caption{$L^1$ norm for CN PLs in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_MCI_H_1_displot.png}
    \caption{$L^1$ norm for MCI PLs in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_AD_H_1_displot.png}
    \caption{$L^1$ norm for AD PLs in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_CN_H_2_displot.png}
    \caption{$L^1$ norm for CN PLs in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_MCI_H_2_displot.png}
    \caption{$L^1$ norm for MCI PLs in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pls/median_pl_AD_H_2_displot.png}
    \caption{$L^1$ norm for AD PLs in $H_2$}
  \end{subfigure}
  \caption{Histogram overlayed with a density estimate showing the distribution of the $L^1$ norm
taken between the median PL for a diagnostic categories in all homological dimensions.}
\label{fig:displots_median_pl}
\end{figure}

\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_CN_H_0_displot.png}
    \caption{$L^1$ norms for CN PIs in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_MCI_H_0_displot.png}
    \caption{$L^1$ norms for MCI PIs in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_AD_H_0_displot.png}
    \caption{$L^1$ norms for AD PIs in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_CN_H_1_displot.png}
    \caption{$L^1$ norms for CN PIs in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_MCI_H_1_displot.png}
    \caption{$L^1$ norms for MCI PIs in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_AD_H_1_displot.png}
    \caption{$L^1$ norms for AD PIs in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_CN_H_2_displot.png}
    \caption{$L^1$ norms for CN PIs in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_MCI_H_2_displot.png}
    \caption{$L^1$ norms for MCI PIs in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/median_pis/median_pi_AD_H_2_displot.png}
    \caption{$L^1$ norms for AD PIs in $H_2$}
  \end{subfigure}
  \caption{Histogram overlayed with a density estimate showing the distribution of the $L^1$ norm
taken between the PI and each image within a diagnostic category in all three homological
dimesions.}
  \label{fig:displots_median_pi}
\end{figure}


\begin{table}
\centering
\begin{tabular}{llllllll}
\toprule
  {} &     Mean &   Median & Std. dev. &       Q3 &       Max & Skewness &    SW \\
\midrule
CN $H_0$  &  $2.145$ &  $2.022$ &             $0.74$ &  $2.457$ &   $7.095$ &  $2.351$ &  $1.9\times10^{-11}$ \\
CN $H_1$  &  $2.669$ &   $2.35$ &            $1.202$ &    $2.9$ &   $7.757$ &  $1.823$ &  $7.2\times10^{-13}$ \\
CN $H_2$  &  $2.293$ &  $2.198$ &            $0.812$ &  $2.647$ &   $5.677$ &  $1.093$ &   $4.6\times10^{-7}$ \\
MCI $H_0$ &  $2.215$ &  $2.063$ &             $0.78$ &  $2.559$ &   $5.609$ &   $1.52$ &  $6.0\times10^{-10}$ \\
  MCI $H_1$ &  $2.592$ &  $2.219$ &            $1.407$ &   $2.85$ &  $11.866$ &  $\mathbf{2.787}$ &  $2.4\times10^{-16}$ \\
MCI $H_2$ &  $2.382$ &  $2.251$ &            $0.815$ &  $2.782$ &   $5.852$ &   $0.95$ &   $2.2\times10^{-6}$ \\
AD $H_0$  &  $2.422$ &  $2.261$ &            $0.813$ &  $2.832$ &   $5.701$ &  $1.189$ &   $1.1\times10^{-5}$ \\
AD $H_1$  &  $2.514$ &  $2.183$ &            $1.172$ &  $2.717$ &   $8.878$ &  $\mathbf{2.395}$ &  $3.6\times10^{-12}$ \\
AD $H_2$  &  $2.237$ &  $2.073$ &            $0.686$ &  $2.637$ &   $5.594$ &  $1.305$ &   $6.1\times10^{-6}$ \\
  \bottomrule
  \vspace{1pt}
\end{tabular}
  \caption{Summary statistics of the distribution of distances from median persistence landscapes for
each diagnostic category shown in Figure \ref{fig:displots_median_pl}. Bold values represent
relatively high values. SW: Shapiro-Wilk test $p$-value}
\label{tab:stats_median_pl}
\end{table}


\begin{table}
\centering
\begin{tabular}{llllllll}
\toprule
  {} &     Mean &   Median & Std. dev. &       Q3 &       Max & Skewness &   SW \\
\midrule
CN $H_0$  &  $3.3\times10^{6}$ &  $3.3\times10^{6}$ &  $4.0\times10^{5}$ &  $3.6\times10^{6}$ &  $4.6\times10^{6}$ &  $5.2\times10^{-1}$ &           $0.006$ \\
CN $H_1$  &  $1.0\times10^{7}$ &  $1.0\times10^{7}$ &  $1.1\times10^{6}$ &  $1.1\times10^{7}$ &  $1.4\times10^{7}$ &  $6.7\times10^{-1}$ &             $0.0$ \\
CN $H_2$  &  $9.7\times10^{6}$ &  $9.4\times10^{6}$ &  $1.1\times10^{6}$ &  $1.0\times10^{7}$ &  $1.3\times10^{7}$ &  $6.4\times10^{-1}$ &             $0.0$ \\
  MCI $H_0$ &  $3.6\times10^{6}$ &  $3.6\times10^{6}$ &  $4.6\times10^{5}$ &  $4.0\times10^{6}$ &  $4.8\times10^{6}$ &  $2.5\times10^{-1}$ &           $\mathbf{0.071}$ \\
MCI $H_1$ &  $7.9\times10^{6}$ &  $7.8\times10^{6}$ &  $8.7\times10^{5}$ &  $8.4\times10^{6}$ &  $1.0\times10^{7}$ &  $3.5\times10^{-1}$ &           $0.018$ \\
  MCI $H_2$ &  $9.1\times10^{6}$ &  $9.0\times10^{6}$ &  $9.9\times10^{5}$ &  $9.8\times10^{6}$ &  $1.1\times10^{7}$ &  $3.4\times10^{-1}$ &           $\mathbf{0.169}$ \\
AD $H_0$  &  $3.8\times10^{6}$ &  $3.8\times10^{6}$ &  $4.1\times10^{5}$ &  $4.1\times10^{6}$ &  $5.0\times10^{6}$ &  $4.8\times10^{-1}$ &           $0.034$ \\
  AD $H_1$  &  $9.1\times10^{6}$ &  $9.0\times10^{6}$ &  $1.0\times10^{6}$ &  $9.9\times10^{6}$ &  $1.2\times10^{7}$ &  $4.4\times10^{-1}$ &           $\mathbf{0.144}$ \\
AD $H_2$  &  $9.2\times10^{6}$ &  $9.1\times10^{6}$ &  $1.0\times10^{6}$ &  $9.9\times10^{6}$ &  $1.1\times10^{7}$ &  $1.0\times10^{-1}$ &           $\mathbf{0.387}$ \\
  \bottomrule
  \vspace{1pt}
\end{tabular}
\caption{Summary statistics of the distribution of distances from median persistence image for each
diagnostic category shown in Figure \ref{fig:displots_median_pi}. Bold values represent
non-significant $p$-values. SW: Shapiro-Wilk test $p$-value.}
\label{tab:stats_median_pi}
\end{table}

\subsubsection{Intra-patient pairwise distance and average $L^1$ norm distributions -- topological
  evolution}

As indicated in section \ref{sec:tda_setup}, we can compute the distance between various PLs
associated with the different timepoints available to a single patient to evaluate the distance
between each of these topological representations at these timepoints, hence obtaining a
representation of the topological evolution of that particular patient. When applying this approach
to the ADNI data, we find interesting qualitative results: distances vary widely from one patient to
the next. For instance, if we take a CN patient diagnosed as such throughout the time that patient
has been monitored, we see relatively low distances between that patients and other timepoints --
see Figure \ref{fig:patient_evolution_stable} for an example. However, distances seem higher when
taking a patient who transitions from an MCI diagnosis to an AD diagnosis, as can be seen in Figure
~\ref{fig:patient_evolution_mci_ad}. Note that the color scale is the same for Figures
\ref{fig:patient_evolution_stable} and \ref{fig:patient_evolution_mci_ad}. However, these effects do
not generalize: if we take the average distance for each homological dimension for each patient and
compare the distribution of these averages for patients who deteriorate (i.e. transition from CN to
MCI or from MCI to AD) and those who do not, we do not see any quantitative difference, as can be
seen in Figure \ref{fig:kde_intra_patient}. Surprisingly, we see that taking the average Wasserstein
distance for each patient, a bimodal -- similar for both deteriorating and stable patients --
distribution arises, but mostly disappears as we let $p\to\infty$ and recover the bottleneck
distance. The cause of the distance change is not known. Additionally, while no substantial
differences are observed, we do see slight rightwards shifts in each mode for both Wasserstein and
the $L^1$ norm of the persistent landscape, indicating a potentially increased distance distribution
among some of the observed data points. Performing a Mann-Whitney $\mathcal{U}$ test on the data
confirms this qualitative finding, by showing that the two distributions shown in Figure
\ref{fig:kde_intra_patient} stem from two different latent distributions ($p<0.01$ for all
distributions).


\begin{figure}[htb]
  \centering \includegraphics[width=0.32\textwidth]{figures/temporal_evolution/ADNI011S0023_h_0.png}
  \hfill \includegraphics[width=0.32\textwidth]{figures/temporal_evolution/ADNI011S0023_h_1.png}
  \hfill
  \includegraphics[width=0.32\textwidth]{figures/temporal_evolution/ADNI011S0023_h_2.png} \caption{Topological
    evolution of a subject with an unchanging CN diagnosis as shown through the pairwise distances
    between the persistence images obtained from the sMRI acquired at several months interval. M00
    refers to the baseline sMRI, M06 refers to the sMRI taken 6 months after the baseline image, etc.}
  \label{fig:patient_evolution_stable}
\end{figure}

\begin{figure}[htb]
  \centering \includegraphics[width=0.32\textwidth]{figures/temporal_evolution/ADNI029S0878_h_0.png}
  \hfill \includegraphics[width=0.32\textwidth]{figures/temporal_evolution/ADNI029S0878_h_1.png}
  \hfill \includegraphics[width=0.32\textwidth]{figures/temporal_evolution/ADNI029S0878_h_2.png}
    \caption{Topological evolution of a patient who transitions from MCI to AD in the course of the
observation. The setup is the same as for Figure \ref{fig:patient_evolution_stable}. For this
particular patient, the change in diagnosis occurred at $t=24$, i.e. 24 months after the earliest
available diagnosis, which also incidentally corresponds with the highest distance from that
baseline.}
    \label{fig:patient_evolution_mci_ad}
\end{figure}


\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/temporal_evolution/wasserstein_H_0_dist_diag_change.png}
    \caption{Wasserstein distance with $p=2$ in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/temporal_evolution/wasserstein_H_1_dist_diag_change.png}
    \caption{Wasserstein distance with $p=2$ in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/temporal_evolution/wasserstein_H_2_dist_diag_change.png}
    \caption{Wasserstein distance with $p=2$ in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/temporal_evolution/bottleneck_H_0_dist_diag_change.png}
    \caption{Bottleneck distance in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/temporal_evolution/bottleneck_H_1_dist_diag_change.png}
    \caption{Bottleneck distance in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/temporal_evolution/bottleneck_H_2_dist_diag_change.png}
    \caption{Bottleneck distance in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/temporal_evolution/landscape_H_0_dist_diag_change.png}
    \caption{$L^{1}$ landscape distance with 1 layer in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/temporal_evolution/landscape_H_1_dist_diag_change.png}
    \caption{$L^{1}$ landscape distance with 1 layer in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/temporal_evolution/landscape_H_2_dist_diag_change.png}
    \caption{$L^{1}$ landscape distance with 1 layer in $H_2$}
  \end{subfigure}
  \caption{Kernel density estimation of the average average distance between each image timepoint
    for each patient. The orange curve represents all those patients who have had at least one
    change in diagnosis over the course of the disease, whereas patients who have not are within the
    blue curve.}
  \label{fig:kde_intra_patient}
\end{figure}

\subsection{Topological outliers and misclassified samples.}

The distribution of distances with respect to the average persistent landscape was plotted for the
patients who were correctly classified, and for those who were not correctly classified. The results
are shown in Figure~\ref{fig:outlier_misclassified}. We also examined the proportion of patients who
switched diagnoses in the whole ADNI dataset. We found that 70\% (64) of the misclassified patients
had only one diagnosis versus 71\% (323) in the whole dataset, hence indicating that misclassified
patients did not contain persistent features that made them more likely to be misclassified.

\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/misclassification_distance/distribution_distance_misclassified_CN_H_0.png}
    \caption{$L^1$ norms CN PL in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/misclassification_distance/distribution_distance_misclassified_CN_H_1.png}
    \caption{$L^1$ norms CN PL in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/misclassification_distance/distribution_distance_misclassified_CN_H_2.png}
    \caption{$L^1$ norms CN PL in $H_2$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/misclassification_distance/distribution_distance_misclassified_AD_H_0.png}
    \caption{$L^1$ norms AD PL in $H_0$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/misclassification_distance/distribution_distance_misclassified_AD_H_1.png}
    \caption{$L^1$ norms AD PL in $H_1$}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/misclassification_distance/distribution_distance_misclassified_AD_H_2.png}
    \caption{$L^1$ norms AD PL in $H_2$}
  \end{subfigure}
    \caption{Kernel density estimation of distribution of the distance between the AD and CN median
      persistence image for images which have not and have been misclassified.}
  \label{fig:outlier_misclassified}
\end{figure}

\subsection{Visualisation of the distance of each patient to the median PI of AD patients and CN patients}

The results of the procedure highlighted in section \ref{sec:methods_dist_multiple_images} is shown
in Figure \ref{fig:vis_pca_ad_cn}. We see that on average AD patients tend to cluster higher up in
the visualization compared to CN subjects. As expected, patients diagnosed with MCI tend to
comingle among AD and CN patients. This trend does not appear using an out-of-the-box mMDS plot, as
can be seen in Figure \ref{fig:mds_plot}. Clear clusters need yet to be defined more clearly using topological
data analysis.

\begin{figure}[htb]
  \centering \includegraphics[width=\textwidth]{figures/cluster_CN_H_2_AD_H_2_PCA.png}
  \caption{Visualisation of the two PCA components obtained from looking at the distance between the
    $L^1$ distance of each image to the median PI of AD and CN in $H_2$.}
  \label{fig:vis_pca_ad_cn}
\end{figure}


\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{figures/mds_plot.png}
  \caption{MDS plot of all diagnostic categories.}
  \label{fig:mds_plot}
\end{figure}

\section{Discussion}\label{sec:discussion}

In this section, we begin by discussing how persistence images provide salient features for the
characterization of atrophy due to Alzheimer's disease and result in competitive classification
performance results; we then move on to discuss our findings regarding the distributions of
distances among diagnostic categories and within patients, also touching upon how distances relate
to misclassified samples. Then, we briefly discuss how taking the distance of each image with
respect to two median persistence images yields trends of clusters of patients. Finally, we outline
some limitations and further research avenues to be explored in the future.

\subsection{Local persistence images are salient features for the characterization of atrophy due to AD }

We obtain competitive performance results when classifying AD and CN subjects using persistence
images obtained from patches, showing that the atrophy observed in AD can be characterized
reasonably reliably from local persistence images (shown in Table ~\ref{tab:performance}). While the
classification performance is lower than the state of the art reported in \citep{liu2018anatomical},
which are about 85\% to 90\% and reported in Table \ref{tab:performance}, our results were obtained
using a very simple neural architecture and only the local topological features of a single, small
patch in the temporal lobe. Additionally, the standard deviation of the performance measures of our
approach seems to be consistently lower than other approaches presented so far for which standard
deviations of performance measures were available. This stability is likely because persistence
homology itself is a stable method, robust to noise present in data \citep{cohen2007stability}, but
this stability is also compounded by the fact that that persistence images have also been proven to
be stable when introducing noise to the underlying persistence diagram \citep{adams2017persistence}.
We note that one of the inherent impediments to our classifiers is that it does not have access to
all the available clinical data contributing to the establishment of a formal diagnosis of
Alzheimer's disease. As per the revised guidelines for the diagnosis of AD, other factors such as
blood and cerebrospinal fluid biomarkers and positron emission tomography (PET) scans also greatly
influence the establishment of an AD diagnosis \citep{mckhann2011diagnosis}.

Signs showing that our accuracy might be improved is that there is no increased ratio of topological
outliers (i.e. PIs showing an unusually high distance w.r.t. the median PL or PI of the diagnostic
category to which the PI belongs) among the misclassified samples
(Figure~\ref{fig:outlier_misclassified}), nor is the the proportion of patients showing a change in
diagnosis substantially higher among misclassified samples, showing that patients who are
oscillating between two diagnostic categories do not account for a high uncertainty. One way to
increase the performance of our models would be a multi-patch setup, where the persistent image of
other relevant patches could be considered. This stems from the fact that there is increasing
evidence for the existence of biological subtypes of AD, which translate into differentially affected
brain regions \citep{poulakis2018heterogeneous, tijms2020pathophysiological}. In this context,
computing the PI of other local areas of the brain which are affected by other subtypes of AD, like
the precuneus, the medial and lateral temporal cortex, some of which incidentally also show
increased accuracy in patch-based classification as seen in Figure~\ref{fig:acc}. Another research
avenue to be explored is the determination of possible weight functions applied to obtain
persistence images to emphasize particularly important landmarks of Alzheimer's disease. Although
theoretically the information contained in a patch PI should be contained in a whole-brain PI, the
amount of noisy features is also much higher, and thereby prevents the CNN to obtain higher
performance on whole-brain PIs. One might consider combining the results of a gradient-weighted
class activation mapping (Grad-CAM) on a raw CNN trained on the patch with the persistence surface
to increase the weight of particular topological features, should they stand out in the persistence
image and yields better classification results.


\subsection{Distances}\label{sec:disc-dist}

We begin the discussion of our distance distribution analyses by showing a somewhat surprising
finding highlighted in Section \label{sec:results_between_images}, specifically in Figure
\ref{fig:median_pls}. This is somewhat contrary to expectation, as we would expect larger, more
persistent holes to appear in brains affected by Alzheimer's disease, resulting in a higher valued
persistent $\lambda_1$ persistent landscape. One possible explanation for this phenomenon is that
the wholes attributed to Alzheimer's disease do not appear as the median most persistent feature at
any given value of the filtration function. Yet, this hypothesis is difficult to prove visually.
This finding highlights the difficulty of the emerging problems of interpretability of persistent
homology when trying to map findings derived from persistent homology back to biological phenomena,
which is an active area of research, for instance in the context of synthesizing neuronal structures
using topological signatures \citep{vanherpe2016framework}.

As shown in Figure \ref{fig:displots_median_pl}, the distribution of the distances of the persistent
landscapes of each patch PL to the median PL for each of these diagnostic categories (shown in
Figure ~\ref{fig:median_pls}) is very skewed, with some patients' PL having a much higher distance
values compared to the rest of the patients (see Table ~\ref{tab:stats_median_pl} and Figure
~\ref{tab:stats_median_pl}). While the overall skew is most pronounced among MCI patients, pointing
to a genuinely increased topological heterogeneity within this particular diagnostic category, some
of the more extreme values can be attributed to noise introduced at any step of the data acquisition
and preprocessing steps described in section \ref{sec:methods}. Note that this phenomenon could also
underlie the heterogeneity of the results we see in the comparisons made within a single patient
(discussed below), indicating that noise probably plays a significant role in defining the distance
among high persistence features obtained from one-layered persistence landscapes.

The aforementioned skewness and heterogeneity are most likely due to the high diversity of persistent
topological features. As highlighted in section
\ref{sec:theory_persistence_landscape_persistence_image}, the persistence landscape of a persistence
diagrams provides a way to select the most persistent features for a given range of filtration
values and given we have taken the first layer of a persistence landscape in our analyses, the
topological heterogeneity mostly concerns the most persistent features. As noted in section
\ref{sec:results_between_images}, this heterogeneity disappears when performing the same type of
analysis using persistence images as vectorized representations for the analysis. We hypothesize
that this change is because persistence images consider all topological features,
regardless of whether or not they are persistent. Hence, when considering all features, the
distribution is mostly even, and topological outliers cannot be identified, save a few exceptions.

Contrary to expectation, little appreciable difference was seen in intra-patient samples across
distance functions. The reason for this lack of signal is likely because the level of
noise introduced by averaging for each patient likely drown any intra-patient evolution signal. More
sensitive clustering techniques using PDs could be more useful to determine the temporal trajectory
of each patient. Additionally, the features extracted from a local patch are most likely
not enough to characterize global atrophy progression patterns seen in the cortex of Alzheimer's
patients over time, as noted by \citep{toniolo2018patterns}.

\subsection{Visualizing PIs using distances to the median PI of AD patients and CN subjects}

We now examine Figure \ref{fig:vis_pca_ad_cn}, which plots the principal components obtained from
computing the $L^1$ norm of each image with respect to the median image in $H_2$. We see some trends
emerging: for instance, we tend to see CN PIs cluster in the upper part of the plot while AD PIs
tend to cluster in the bottom, with MCI patients mostly blended in between. Yet, these trends are
not clear enough to obtain clear clusters of disease phenotypes (i.e. one associated with each
condition), let alone disease subtypes. It should be noted that the approach presented here to
cluster patients still performs qualitatively better than out-of-the-box embedding approaches such
as mMDS plots as shown in Figure \ref{fig:mds_plot}. Obtaining features more salient for clustering
various subtypes would probably require more complex features, extracted for instance using a
dynamic autoencoder on the persistence images \citep{mrabah2019deep}. Additionally, other methods
tailored for topological features might also be developed and applied here.

\subsection{Limitations and outlook}

The first drawback of our analysis is the difficulty to highlight sources of noise in high
persistence features. For instance, we mention in section \ref{sec:disc-dist} that some of the
topological outliers that were highlighted in Figure \ref{fig:displots_median_pl} (but also observed
among AD patients in Figure \ref{fig:vis_pca_ad_cn}) could be due to noise, but the source of this
noise is unknown. Specifically, it is not possible to investigate whether this noise comes from the
preprocessing pipeline applied to it, or from the latent data distribution. We hypothesize that part
of the noise could be introduced during the mapping of the original T1-weighted image to the
reference normalized MNI space since it is the step that is most likely to introduce artificial
noise in our data except the data itself \citep{collins19943d}, but it is impossible in the
current setup to show evidence that this step in the preprocessing process is the root of the skewed
distribution, or whether these changes can be attributed to intra-individual anatomical variance.

Another general limitation of the findings presented here is the coarseness of the analyses related
to distances. While we wanted to get an insight into the rawest form of the data possible, taking
the $L^1$ norm between some vector representations of the persistence diagram for instance can
artificially drown highly discriminatory features. Therefore, the potential of the topological
features to discriminate between patients who progress from a baseline diagnosis or not can be
further investigated using more optimized clustering techniques making use of the topological
features extracted using persistent homology.

More specifically, some coarseness was deliberately introduced by extracting only one layer when
analyzing persistence landscapes. This value was chosen because we are interested in changes in the
highly persistent features of the data, hence eliminating the noise arising from the persistent
homology computation. On a similar note, the performance of our classifier could have further be
optimized using a deeper and more optimized architecture, but the choice of a simple architecture
was made to assess the saliency of the data rather than the potential of the classifier itself to
yield good results with little computation.

Our classification task does not cover the full spectrum of all of the possible diagnoses a patient
coming to a memory clinic might present. Importantly, our model was not trained to classify patients
who have a case of MCI, which is neither AD nor CN, but in between. The
discriminatory power of the features used in this report do not enable the full-fledged
diagnostic classification task required in the clinic. Further studies need to also assess the
saliency of the PI obtained from the temporal patch in question for a better assessment of the
clinical usefulness of persistent homology in classifying the various categories of patients.

Despite these limitations, it is important to point out that the approach outlined here was
specifically aimed at analyzing MRI images obtained from patients with Alzheimer's disease, it could
also be applied to any other neurodegenerative disorder. Other prevalent neurodegenerative disorders
include Parkinson's disease, dementia with Lewy bodies, and genetically inherited diseases like
Huntington's disease, which all have distinct atrophy patterns and therefore distinct topological signatures.
Adaptations would be required, such as adapting the choice of a patch of interest -- as an example, it
might be more relevant to look at the basal ganglia for Huntington's disease, since the medial
temporal lobe is observed to be mostly spared in Huntington's
\citep{kuhl1982cerebral, halliday1998regional, kassubek2004topography}.

Additionally, we note that a clustering using topological descriptors could be used to more finely
delineate subtypes of AD and various stages of progression. For instance, using deep clustering
techniques and embeddings using persistence images as inputs could yield useful insights into the
various stages of progression and subtypes of dementia. These more sensitive methods could then,
once fine-tuned, hopefully also track preclinical stages of AD, when atrophy is present but does not
result in cognitive decline due to the presence of a cognitive reserve
\citep{scarmeas2004cognitive, van2017neuroimaging}. The identification of patient populations at
risk of developing the disease could then form the target of any potential preventive treatment.

\section{Conclusions}

In this report we have shown that PIs computed from a patch in the temporal lobe are salient for
classifying CN and AD subjects. Additionally, we show that the distribution of distances among the
patients in each of the diagnostic category is skewed, indicating the presence of topological
outliers, but, overall, does not affect the classification performance. Then, we show a significant,
but not substantial, increase in distance among images belonging to a given patient who deteriorates
towards Alzheimer's disease versus patients who do not. Our last finding is that clustering patients
solely according to their distance with respect to multiple median PI does not allow proper AD
subtype identification, be shows a promising research avenue. Although promising, all of these
topology-driven approaches need further development to maximize the information that can be
extracted from MRI images.

\clearpage
\bibliographystyle{unsrtnat}
\bibliography{main}

\clearpage
\appendix

\section{Supplements}
\subsection{Preprocessing of MRI data}\label{apd:preprocessing}
We included all T1-weighted MRI images from ADNI 1, 2, 3, and GO, which were captured and
preprocessed by ADNI. Results included in our work come from preprocessing performed using
\texttt{fMRIPrep} 20.1.1, a Nipype 1.5.0 based tool. All MRIs were corrected for intensity
non-uniformity (INU) with \texttt{N4BiasFieldCorrection}, distributed with ANTs 2.2.0, and used as
T1w-reference throughout the workflow. The T1w-reference was then skull-stripped with a
\texttt{Nipype} implementation of the \texttt{antsBrainExtraction.sh} workflow (from ANTs), using
\texttt{OASIS30ANTs} as a target template.
%Brain tissue segmentation of cerebrospinal fluid (CSF),
%white-matter (WM) and gray-matter (GM) was performed on
%the brain-extracted T1w using `fast` [FSL 5.0.7]. %, RRID:SCR_002823, @fsl_fast].
Volume-based spatial normalisation to a standard coordinate space~(\texttt{MNI152NLin2009cAsym}) was
performed through nonlinear registration with \texttt{antsRegistration}, using brain-extracted
versions of both T1w reference and the T1w template. We slected the template `ICMB 152 Nonlinear
Asymmetrical Template Version 2009c' for spatial normalisation.
% [@mni152nlin2009casym, RRID:SCR_008796; TemplateFlow ID: MNI152NLin2009cAsym],
Many internal operations of \texttt{fMRIPrep} use the
\texttt{Nilearn} library, version 0.6.2, % [@nilearn, RRID:SCR_001362]
, mostly within the functional processing workflow.
For more details of the pipeline, please refer to
\href{https://fMRIPrep.readthedocs.io/en/latest/workflows.html}{the official documentation of
  \texttt{fMRIPrep}}. Preprocessing was finalized by intensity normalization of the extracted and
MNI space registered brain images.


\end{document}
